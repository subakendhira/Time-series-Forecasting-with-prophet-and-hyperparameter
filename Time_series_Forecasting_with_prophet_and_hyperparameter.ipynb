{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Prophet and optimization libraries\n",
        "from prophet import Prophet\n",
        "from prophet.diagnostics import cross_validation, performance_metrics\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "\n",
        "# Baseline models\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "import json\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# Visualization settings\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (14, 6)\n",
        "\n",
        "#==============================================================================\n",
        "# TASK 1: DATA GENERATION\n",
        "#==============================================================================\n",
        "\n",
        "class SyntheticRetailDataGenerator:\n",
        "    \"\"\"\n",
        "    Generates synthetic retail sales data with multiple seasonal patterns\n",
        "    and holiday effects suitable for Prophet modeling.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, start_date='2020-01-01', periods=1095, freq='D'):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -----------\n",
        "        start_date : str\n",
        "            Start date for the time series\n",
        "        periods : int\n",
        "            Number of data points (minimum 1095 for 3 years daily data)\n",
        "        freq : str\n",
        "            Frequency of data ('D' for daily)\n",
        "        \"\"\"\n",
        "        self.start_date = start_date\n",
        "        self.periods = periods\n",
        "        self.freq = freq\n",
        "        self.date_range = pd.date_range(start=start_date, periods=periods, freq=freq)\n",
        "\n",
        "    def generate_trend(self, changepoints=[365, 730]):\n",
        "        \"\"\"Generate non-linear trend with changepoints\"\"\"\n",
        "        t = np.arange(self.periods)\n",
        "        trend = 1000 + 2 * t  # Base upward trend\n",
        "\n",
        "        # Add changepoints\n",
        "        for cp in changepoints:\n",
        "            if cp < self.periods:\n",
        "                trend[cp:] += 500 * (1 - np.exp(-0.003 * (t[cp:] - cp)))\n",
        "\n",
        "        return trend\n",
        "\n",
        "    def generate_yearly_seasonality(self):\n",
        "        \"\"\"Generate yearly seasonal pattern\"\"\"\n",
        "        day_of_year = self.date_range.dayofyear\n",
        "        yearly = 300 * np.sin(2 * np.pi * day_of_year / 365.25)\n",
        "        return yearly\n",
        "\n",
        "    def generate_weekly_seasonality(self):\n",
        "        \"\"\"Generate weekly seasonal pattern (lower sales on weekends)\"\"\"\n",
        "        day_of_week = self.date_range.dayofweek\n",
        "        weekly = np.zeros(self.periods)\n",
        "\n",
        "        # Weekend effect (lower sales)\n",
        "        weekend_mask = (day_of_week >= 5)\n",
        "        weekly[weekend_mask] = -200\n",
        "\n",
        "        # Mid-week peak\n",
        "        midweek_mask = (day_of_week == 2) | (day_of_week == 3)\n",
        "        weekly[midweek_mask] = 150\n",
        "\n",
        "        return weekly\n",
        "\n",
        "    def generate_holiday_effects(self):\n",
        "        \"\"\"Generate three major holiday effects\"\"\"\n",
        "        holiday_effect = np.zeros(self.periods)\n",
        "\n",
        "        for date in self.date_range:\n",
        "            year = date.year\n",
        "\n",
        "            # Holiday 1: New Year's Day (Jan 1) - 5 day effect\n",
        "            new_year = pd.Timestamp(f'{year}-01-01')\n",
        "            if abs((date - new_year).days) <= 2:\n",
        "                holiday_effect[self.date_range.get_loc(date)] = 800\n",
        "\n",
        "            # Holiday 2: Black Friday (4th Friday of November) - 7 day effect\n",
        "            november_first = pd.Timestamp(f'{year}-11-01')\n",
        "            black_friday = november_first + pd.DateOffset(days=(3 - november_first.dayofweek) % 7 + 21)\n",
        "            if abs((date - black_friday).days) <= 3:\n",
        "                holiday_effect[self.date_range.get_loc(date)] = 1200\n",
        "\n",
        "            # Holiday 3: Christmas (Dec 25) - 10 day effect\n",
        "            christmas = pd.Timestamp(f'{year}-12-25')\n",
        "            days_to_christmas = (date - christmas).days\n",
        "            if -7 <= days_to_christmas <= 2:\n",
        "                # Ramp up before Christmas, drop after\n",
        "                if days_to_christmas < 0:\n",
        "                    holiday_effect[self.date_range.get_loc(date)] = 1000 * (1 + days_to_christmas / 7)\n",
        "                else:\n",
        "                    holiday_effect[self.date_range.get_loc(date)] = 600\n",
        "\n",
        "        return holiday_effect\n",
        "\n",
        "    def generate_noise(self, scale=100):\n",
        "        \"\"\"Generate random noise\"\"\"\n",
        "        return np.random.normal(0, scale, self.periods)\n",
        "\n",
        "    def generate_dataset(self):\n",
        "        \"\"\"Generate complete synthetic dataset\"\"\"\n",
        "        trend = self.generate_trend()\n",
        "        yearly = self.generate_yearly_seasonality()\n",
        "        weekly = self.generate_weekly_seasonality()\n",
        "        holidays = self.generate_holiday_effects()\n",
        "        noise = self.generate_noise()\n",
        "\n",
        "        # Combine all components\n",
        "        sales = trend + yearly + weekly + holidays + noise\n",
        "\n",
        "        # Ensure non-negative values\n",
        "        sales = np.maximum(sales, 100)\n",
        "\n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame({\n",
        "            'ds': self.date_range,\n",
        "            'y': sales,\n",
        "            'trend': trend,\n",
        "            'yearly_seasonality': yearly,\n",
        "            'weekly_seasonality': weekly,\n",
        "            'holiday_effect': holidays\n",
        "        })\n",
        "\n",
        "        return df\n",
        "\n",
        "    def create_holiday_dataframe(self):\n",
        "        \"\"\"Create holiday dataframe for Prophet\"\"\"\n",
        "        holidays = []\n",
        "\n",
        "        years = range(2020, 2024)\n",
        "\n",
        "        for year in years:\n",
        "            # New Year's Day\n",
        "            holidays.append({\n",
        "                'holiday': 'new_year',\n",
        "                'ds': pd.Timestamp(f'{year}-01-01'),\n",
        "                'lower_window': -2,\n",
        "                'upper_window': 2\n",
        "            })\n",
        "\n",
        "            # Black Friday\n",
        "            november_first = pd.Timestamp(f'{year}-11-01')\n",
        "            black_friday = november_first + pd.DateOffset(days=(3 - november_first.dayofweek) % 7 + 21)\n",
        "            holidays.append({\n",
        "                'holiday': 'black_friday',\n",
        "                'ds': black_friday,\n",
        "                'lower_window': -3,\n",
        "                'upper_window': 3\n",
        "            })\n",
        "\n",
        "            # Christmas\n",
        "            holidays.append({\n",
        "                'holiday': 'christmas',\n",
        "                'ds': pd.Timestamp(f'{year}-12-25'),\n",
        "                'lower_window': -7,\n",
        "                'upper_window': 2\n",
        "            })\n",
        "\n",
        "        return pd.DataFrame(holidays)\n",
        "\n",
        "#==============================================================================\n",
        "# TASK 2: CROSS-VALIDATION STRATEGY\n",
        "#==============================================================================\n",
        "\n",
        "class TimeSeriesCrossValidator:\n",
        "    \"\"\"\n",
        "    Implements robust time series cross-validation strategies\n",
        "    including rolling window and expanding window methods.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, initial_train_size=730, horizon=90, period=90, method='rolling'):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -----------\n",
        "        initial_train_size : int\n",
        "            Initial training period in days (2 years = 730 days)\n",
        "        horizon : int\n",
        "            Forecast horizon in days (90 days = ~3 months)\n",
        "        period : int\n",
        "            Spacing between cutoff dates in days\n",
        "        method : str\n",
        "            'rolling' or 'expanding' window\n",
        "        \"\"\"\n",
        "        self.initial_train_size = initial_train_size\n",
        "        self.horizon = horizon\n",
        "        self.period = period\n",
        "        self.method = method\n",
        "\n",
        "    def split_data(self, df, test_size=90):\n",
        "        \"\"\"\n",
        "        Split data into train and test sets\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        df : pd.DataFrame\n",
        "            Full dataset\n",
        "        test_size : int\n",
        "            Size of test set in days\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        train_df, test_df : tuple\n",
        "            Training and test dataframes\n",
        "        \"\"\"\n",
        "        split_idx = len(df) - test_size\n",
        "        train_df = df.iloc[:split_idx].copy()\n",
        "        test_df = df.iloc[split_idx:].copy()\n",
        "\n",
        "        return train_df, test_df\n",
        "\n",
        "    def prophet_cross_validation(self, model, train_df):\n",
        "        \"\"\"\n",
        "        Perform Prophet's built-in cross-validation\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        model : Prophet\n",
        "            Fitted Prophet model\n",
        "        train_df : pd.DataFrame\n",
        "            Training data\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        cv_results : pd.DataFrame\n",
        "            Cross-validation results with predictions and actuals\n",
        "        \"\"\"\n",
        "        # Calculate initial training period\n",
        "        initial_str = f'{self.initial_train_size} days'\n",
        "        period_str = f'{self.period} days'\n",
        "        horizon_str = f'{self.horizon} days'\n",
        "\n",
        "        cv_results = cross_validation(\n",
        "            model,\n",
        "            initial=initial_str,\n",
        "            period=period_str,\n",
        "            horizon=horizon_str,\n",
        "            parallel=\"processes\"\n",
        "        )\n",
        "\n",
        "        return cv_results\n",
        "\n",
        "    def calculate_cv_metrics(self, cv_results):\n",
        "        \"\"\"\n",
        "        Calculate performance metrics from cross-validation results\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        cv_results : pd.DataFrame\n",
        "            Cross-validation results from Prophet\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        metrics : dict\n",
        "            Dictionary of performance metrics\n",
        "        \"\"\"\n",
        "        # Calculate metrics\n",
        "        perf_metrics = performance_metrics(cv_results, rolling_window=0.1)\n",
        "\n",
        "        # Aggregate metrics\n",
        "        metrics = {\n",
        "            'rmse': perf_metrics['rmse'].mean(),\n",
        "            'mape': perf_metrics['mape'].mean(),\n",
        "            'mase': perf_metrics['mase'].mean() if 'mase' in perf_metrics.columns else None,\n",
        "            'mae': perf_metrics['mae'].mean()\n",
        "        }\n",
        "\n",
        "        return metrics, perf_metrics\n",
        "\n",
        "#==============================================================================\n",
        "# TASK 3: HYPERPARAMETER OPTIMIZATION\n",
        "#==============================================================================\n",
        "\n",
        "class ProphetHyperparameterOptimizer:\n",
        "    \"\"\"\n",
        "    Implements Bayesian hyperparameter optimization for Prophet using Optuna.\n",
        "    Searches over key parameters including seasonality modes, changepoint\n",
        "    prior scale, and seasonality strength.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, train_df, holidays_df, cv_strategy):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -----------\n",
        "        train_df : pd.DataFrame\n",
        "            Training data\n",
        "        holidays_df : pd.DataFrame\n",
        "            Holiday definitions\n",
        "        cv_strategy : TimeSeriesCrossValidator\n",
        "            Cross-validation strategy\n",
        "        \"\"\"\n",
        "        self.train_df = train_df\n",
        "        self.holidays_df = holidays_df\n",
        "        self.cv_strategy = cv_strategy\n",
        "        self.best_params = None\n",
        "        self.best_score = None\n",
        "        self.study = None\n",
        "\n",
        "    def objective(self, trial):\n",
        "        \"\"\"\n",
        "        Optuna objective function for hyperparameter optimization\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        trial : optuna.Trial\n",
        "            Optuna trial object\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        cv_rmse : float\n",
        "            Cross-validated RMSE (to be minimized)\n",
        "        \"\"\"\n",
        "        # Define hyperparameter search space\n",
        "        params = {\n",
        "            'changepoint_prior_scale': trial.suggest_float('changepoint_prior_scale', 0.001, 0.5, log=True),\n",
        "            'seasonality_prior_scale': trial.suggest_float('seasonality_prior_scale', 0.01, 10, log=True),\n",
        "            'holidays_prior_scale': trial.suggest_float('holidays_prior_scale', 0.01, 10, log=True),\n",
        "            'seasonality_mode': trial.suggest_categorical('seasonality_mode', ['additive', 'multiplicative']),\n",
        "            'changepoint_range': trial.suggest_float('changepoint_range', 0.8, 0.95),\n",
        "            'yearly_seasonality': trial.suggest_categorical('yearly_seasonality', [10, 15, 20]),\n",
        "            'weekly_seasonality': trial.suggest_categorical('weekly_seasonality', [3, 5, 7]),\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # Initialize Prophet with suggested parameters\n",
        "            model = Prophet(\n",
        "                changepoint_prior_scale=params['changepoint_prior_scale'],\n",
        "                seasonality_prior_scale=params['seasonality_prior_scale'],\n",
        "                holidays_prior_scale=params['holidays_prior_scale'],\n",
        "                seasonality_mode=params['seasonality_mode'],\n",
        "                changepoint_range=params['changepoint_range'],\n",
        "                yearly_seasonality=params['yearly_seasonality'],\n",
        "                weekly_seasonality=params['weekly_seasonality'],\n",
        "                daily_seasonality=False,\n",
        "                holidays=self.holidays_df\n",
        "            )\n",
        "\n",
        "            # Fit model\n",
        "            model.fit(self.train_df)\n",
        "\n",
        "            # Perform cross-validation\n",
        "            cv_results = self.cv_strategy.prophet_cross_validation(model, self.train_df)\n",
        "\n",
        "            # Calculate RMSE\n",
        "            cv_rmse = np.sqrt(mean_squared_error(cv_results['y'], cv_results['yhat']))\n",
        "\n",
        "            return cv_rmse\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Trial failed: {e}\")\n",
        "            return float('inf')\n",
        "\n",
        "    def optimize(self, n_trials=50, timeout=3600):\n",
        "        \"\"\"\n",
        "        Run Bayesian optimization\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        n_trials : int\n",
        "            Number of optimization trials\n",
        "        timeout : int\n",
        "            Maximum optimization time in seconds\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        best_params : dict\n",
        "            Best hyperparameter configuration\n",
        "        \"\"\"\n",
        "        # Create Optuna study\n",
        "        self.study = optuna.create_study(\n",
        "            direction='minimize',\n",
        "            sampler=TPESampler(seed=42)\n",
        "        )\n",
        "\n",
        "        # Run optimization\n",
        "        print(f\"Starting hyperparameter optimization with {n_trials} trials...\")\n",
        "        self.study.optimize(self.objective, n_trials=n_trials, timeout=timeout, show_progress_bar=True)\n",
        "\n",
        "        # Store best parameters\n",
        "        self.best_params = self.study.best_params\n",
        "        self.best_score = self.study.best_value\n",
        "\n",
        "        print(f\"\\nOptimization complete!\")\n",
        "        print(f\"Best RMSE: {self.best_score:.2f}\")\n",
        "        print(f\"Best parameters: {json.dumps(self.best_params, indent=2)}\")\n",
        "\n",
        "        return self.best_params\n",
        "\n",
        "    def get_optimization_history(self):\n",
        "        \"\"\"\n",
        "        Get optimization history for visualization\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        history_df : pd.DataFrame\n",
        "            Optimization history with trial number and objective values\n",
        "        \"\"\"\n",
        "        trials_df = self.study.trials_dataframe()\n",
        "        return trials_df\n",
        "\n",
        "#==============================================================================\n",
        "# TASK 4: MODEL TRAINING AND BASELINE COMPARISON\n",
        "#==============================================================================\n",
        "\n",
        "class ModelComparison:\n",
        "    \"\"\"\n",
        "    Trains optimized Prophet model and compares against baseline models\n",
        "    (ARIMA and Naive Seasonal Forecast) on held-out test set.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, train_df, test_df, holidays_df):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -----------\n",
        "        train_df : pd.DataFrame\n",
        "            Training data\n",
        "        test_df : pd.DataFrame\n",
        "            Test data\n",
        "        holidays_df : pd.DataFrame\n",
        "            Holiday definitions\n",
        "        \"\"\"\n",
        "        self.train_df = train_df\n",
        "        self.test_df = test_df\n",
        "        self.holidays_df = holidays_df\n",
        "        self.models = {}\n",
        "        self.predictions = {}\n",
        "        self.metrics = {}\n",
        "\n",
        "    def train_prophet(self, params):\n",
        "        \"\"\"\n",
        "        Train Prophet model with optimized parameters\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        params : dict\n",
        "            Optimized hyperparameters\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        model : Prophet\n",
        "            Trained Prophet model\n",
        "        \"\"\"\n",
        "        model = Prophet(\n",
        "            changepoint_prior_scale=params['changepoint_prior_scale'],\n",
        "            seasonality_prior_scale=params['seasonality_prior_scale'],\n",
        "            holidays_prior_scale=params['holidays_prior_scale'],\n",
        "            seasonality_mode=params['seasonality_mode'],\n",
        "            changepoint_range=params['changepoint_range'],\n",
        "            yearly_seasonality=params['yearly_seasonality'],\n",
        "            weekly_seasonality=params['weekly_seasonality'],\n",
        "            daily_seasonality=False,\n",
        "            holidays=self.holidays_df\n",
        "        )\n",
        "\n",
        "        model.fit(self.train_df)\n",
        "        self.models['prophet'] = model\n",
        "\n",
        "        return model\n",
        "\n",
        "    def predict_prophet(self):\n",
        "        \"\"\"Generate predictions using Prophet\"\"\"\n",
        "        model = self.models['prophet']\n",
        "        forecast = model.predict(self.test_df[['ds']])\n",
        "        self.predictions['prophet'] = forecast['yhat'].values\n",
        "\n",
        "        return self.predictions['prophet']\n",
        "\n",
        "    def train_arima(self, order=(2, 1, 2), seasonal_order=(1, 1, 1, 7)):\n",
        "        \"\"\"\n",
        "        Train ARIMA/SARIMA baseline model\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        order : tuple\n",
        "            ARIMA order (p, d, q)\n",
        "        seasonal_order : tuple\n",
        "            Seasonal order (P, D, Q, s)\n",
        "        \"\"\"\n",
        "        try:\n",
        "            from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "            model = SARIMAX(\n",
        "                self.train_df['y'],\n",
        "                order=order,\n",
        "                seasonal_order=seasonal_order,\n",
        "                enforce_stationarity=False,\n",
        "                enforce_invertibility=False\n",
        "            )\n",
        "\n",
        "            fitted_model = model.fit(disp=False, maxiter=200)\n",
        "            self.models['arima'] = fitted_model\n",
        "\n",
        "            # Generate predictions\n",
        "            predictions = fitted_model.forecast(steps=len(self.test_df))\n",
        "            self.predictions['arima'] = predictions.values\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"ARIMA training failed: {e}\")\n",
        "            # Fallback to simpler model\n",
        "            self.predictions['arima'] = np.full(len(self.test_df), self.train_df['y'].mean())\n",
        "\n",
        "    def naive_seasonal_forecast(self, season_length=7):\n",
        "        \"\"\"\n",
        "        Create naive seasonal forecast baseline\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        season_length : int\n",
        "            Seasonal period (7 for weekly seasonality)\n",
        "        \"\"\"\n",
        "        # Use last season's values as forecast\n",
        "        last_season = self.train_df['y'].iloc[-season_length:].values\n",
        "\n",
        "        # Repeat to match test set length\n",
        "        n_repeats = int(np.ceil(len(self.test_df) / season_length))\n",
        "        naive_pred = np.tile(last_season, n_repeats)[:len(self.test_df)]\n",
        "\n",
        "        self.predictions['naive_seasonal'] = naive_pred\n",
        "\n",
        "    def calculate_mase(self, y_true, y_pred, y_train):\n",
        "        \"\"\"\n",
        "        Calculate Mean Absolute Scaled Error\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        y_true : array\n",
        "            Actual values\n",
        "        y_pred : array\n",
        "            Predicted values\n",
        "        y_train : array\n",
        "            Training data for scaling\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        mase : float\n",
        "            MASE metric\n",
        "        \"\"\"\n",
        "        mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "        # Calculate naive forecast MAE on training data\n",
        "        naive_mae = np.mean(np.abs(np.diff(y_train)))\n",
        "\n",
        "        if naive_mae == 0:\n",
        "            return np.inf\n",
        "\n",
        "        mase = mae / naive_mae\n",
        "        return mase\n",
        "\n",
        "    def evaluate_models(self):\n",
        "        \"\"\"\n",
        "        Calculate performance metrics for all models\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        metrics_df : pd.DataFrame\n",
        "            DataFrame containing metrics for all models\n",
        "        \"\"\"\n",
        "        y_true = self.test_df['y'].values\n",
        "        y_train = self.train_df['y'].values\n",
        "\n",
        "        metrics_list = []\n",
        "\n",
        "        for model_name, y_pred in self.predictions.items():\n",
        "            rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "            mae = mean_absolute_error(y_true, y_pred)\n",
        "            mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
        "            mase = self.calculate_mase(y_true, y_pred, y_train)\n",
        "\n",
        "            metrics_list.append({\n",
        "                'Model': model_name.upper(),\n",
        "                'RMSE': rmse,\n",
        "                'MAE': mae,\n",
        "                'MAPE': mape,\n",
        "                'MASE': mase\n",
        "            })\n",
        "\n",
        "            self.metrics[model_name] = {\n",
        "                'rmse': rmse,\n",
        "                'mae': mae,\n",
        "                'mape': mape,\n",
        "                'mase': mase\n",
        "            }\n",
        "\n",
        "        metrics_df = pd.DataFrame(metrics_list)\n",
        "        return metrics_df\n",
        "\n",
        "#==============================================================================\n",
        "# TASK 5: ANALYSIS AND VISUALIZATION\n",
        "#==============================================================================\n",
        "\n",
        "class ResultsAnalyzer:\n",
        "    \"\"\"\n",
        "    Provides comprehensive analysis and visualization of results including\n",
        "    hyperparameter importance, model comparisons, and forecast visualizations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_generator, optimizer, model_comparison):\n",
        "        \"\"\"\n",
        "        Parameters:\n",
        "        -----------\n",
        "        data_generator : SyntheticRetailDataGenerator\n",
        "            Data generator instance\n",
        "        optimizer : ProphetHyperparameterOptimizer\n",
        "            Hyperparameter optimizer instance\n",
        "        model_comparison : ModelComparison\n",
        "            Model comparison instance\n",
        "        \"\"\"\n",
        "        self.data_generator = data_generator\n",
        "        self.optimizer = optimizer\n",
        "        self.model_comparison = model_comparison\n",
        "\n",
        "    def plot_data_components(self, df):\n",
        "        \"\"\"Visualize the generated data and its components\"\"\"\n",
        "        fig, axes = plt.subplots(5, 1, figsize=(14, 12))\n",
        "\n",
        "        # Full time series\n",
        "        axes[0].plot(df['ds'], df['y'], label='Sales', color='blue', linewidth=1)\n",
        "        axes[0].set_title('Generated Retail Sales Data', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_ylabel('Sales')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Trend\n",
        "        axes[1].plot(df['ds'], df['trend'], label='Trend', color='green', linewidth=1.5)\n",
        "        axes[1].set_title('Trend Component', fontsize=12)\n",
        "        axes[1].set_ylabel('Trend')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Yearly seasonality\n",
        "        axes[2].plot(df['ds'], df['yearly_seasonality'], label='Yearly Seasonality', color='orange', linewidth=1)\n",
        "        axes[2].set_title('Yearly Seasonal Component', fontsize=12)\n",
        "        axes[2].set_ylabel('Yearly Effect')\n",
        "        axes[2].legend()\n",
        "        axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "        # Weekly seasonality\n",
        "        axes[3].plot(df['ds'], df['weekly_seasonality'], label='Weekly Seasonality', color='purple', linewidth=1)\n",
        "        axes[3].set_title('Weekly Seasonal Component', fontsize=12)\n",
        "        axes[3].set_ylabel('Weekly Effect')\n",
        "        axes[3].legend()\n",
        "        axes[3].grid(True, alpha=0.3)\n",
        "\n",
        "        # Holiday effects\n",
        "        axes[4].plot(df['ds'], df['holiday_effect'], label='Holiday Effects', color='red', linewidth=1)\n",
        "        axes[4].set_title('Holiday Effect Component', fontsize=12)\n",
        "        axes[4].set_ylabel('Holiday Effect')\n",
        "        axes[4].set_xlabel('Date')\n",
        "        axes[4].legend()\n",
        "        axes[4].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('data_components.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        print(\"✓ Data components visualization saved as 'data_components.png'\")\n",
        "\n",
        "    def plot_optimization_history(self):\n",
        "        \"\"\"Visualize hyperparameter optimization progress\"\"\"\n",
        "        trials_df = self.optimizer.get_optimization_history()\n",
        "\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "        # Optimization progress\n",
        "        axes[0].plot(trials_df['number'], trials_df['value'], marker='o', markersize=4, alpha=0.6)\n",
        "        axes[0].axhline(y=self.optimizer.best_score, color='r', linestyle='--',\n",
        "                       label=f'Best: {self.optimizer.best_score:.2f}')\n",
        "        axes[0].set_xlabel('Trial Number')\n",
        "        axes[0].set_ylabel('CV RMSE')\n",
        "        axes[0].set_title('Optimization Progress', fontweight='bold')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Parameter importance (if available)\n",
        "        try:\n",
        "            importance = optuna.importance.get_param_importances(self.optimizer.study)\n",
        "            params = list(importance.keys())\n",
        "            values = list(importance.values())\n",
        "\n",
        "            axes[1].barh(params, values, color='steelblue')\n",
        "            axes[1].set_xlabel('Importance')\n",
        "            axes[1].set_title('Hyperparameter Importance', fontweight='bold')\n",
        "            axes[1].grid(True, alpha=0.3, axis='x')\n",
        "        except:\n",
        "            axes[1].text(0.5, 0.5, 'Importance calculation unavailable',\n",
        "                        ha='center', va='center', transform=axes[1].transAxes)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('optimization_history.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        print(\"✓ Optimization history visualization saved as 'optimization_history.png'\")\n",
        "\n",
        "    def plot_model_comparison(self):\n",
        "        \"\"\"Visualize predictions from all models\"\"\"\n",
        "        test_df = self.model_comparison.test_df\n",
        "\n",
        "        fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
        "\n",
        "        # Full test period comparison\n",
        "        axes[0].plot(test_df['ds'], test_df['y'], label='Actual', color='black',\n",
        "                    linewidth=2, marker='o', markersize=3, alpha=0.7)\n",
        "\n",
        "        colors = {'prophet': 'blue', 'arima': 'red', 'naive_seasonal': 'green'}\n",
        "        for model_name, predictions in self.model_comparison.predictions.items():\n",
        "            axes[0].plot(test_df['ds'], predictions, label=model_name.upper(),\n",
        "                        color=colors[model_name], linewidth=1.5, alpha=0.7)\n",
        "\n",
        "        axes[0].set_title('Model Predictions Comparison (Full Test Period)', fontsize=12, fontweight='bold')\n",
        "        axes[0].set_ylabel('Sales')\n",
        "        axes[0].legend(loc='upper left')\n",
        "        axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Zoomed view (first 30 days)\n",
        "        zoom_days = 30\n",
        "        axes[1].plot(test_df['ds'][:zoom_days], test_df['y'][:zoom_days],\n",
        "                    label='Actual', color='black', linewidth=2, marker='o', markersize=4, alpha=0.7)\n",
        "\n",
        "        for model_name, predictions in self.model_comparison.predictions.items():\n",
        "            axes[1].plot(test_df['ds'][:zoom_days], predictions[:zoom_days],\n",
        "                        label=model_name.upper(), color=colors[model_name],\n",
        "                        linewidth=1.5, marker='s', markersize=3, alpha=0.7)\n",
        "\n",
        "        axes[1].set_title(f'Model Predictions Comparison (First {zoom_days} Days)', fontsize=12, fontweight='bold')\n",
        "        axes[1].set_xlabel('Date')\n",
        "        axes[1].set_ylabel('Sales')\n",
        "        axes[1].legend(loc='upper left')\n",
        "        axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        print(\"✓ Model comparison visualization saved as 'model_comparison.png'\")\n",
        "\n",
        "    def plot_metrics_comparison(self, metrics_df):\n",
        "        \"\"\"Visualize performance metrics comparison\"\"\"\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "        metrics = ['RMSE', 'MAE', 'MAPE', 'MASE']\n",
        "\n",
        "        for idx, metric in enumerate(metrics):\n",
        "            ax = axes[idx // 2, idx % 2]\n",
        "\n",
        "            bars = ax.bar(metrics_df['Model'], metrics_df[metric], color=['blue', 'red', 'green'], alpha=0.7)\n",
        "            ax.set_title(f'{metric} Comparison', fontsize=12, fontweight='bold')\n",
        "            ax.set_ylabel(metric)\n",
        "            ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "            # Add value labels on bars\n",
        "            for bar in bars:\n",
        "                height = bar.get_height()\n",
        "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                       f'{height:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('metrics_comparison.png', dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "        print(\"✓ Metrics comparison visualization saved as 'metrics_comparison.png'\")\n",
        "\n",
        "    def generate_report(self, metrics_df, full_df):\n",
        "        \"\"\"Generate comprehensive text report\"\"\"\n",
        "        report = []\n",
        "        report.append(\"=\"*80)\n",
        "        report.append(\"ADVANCED TIME SERIES FORECASTING - COMPREHENSIVE REPORT\")\n",
        "        report.append(\"=\"*80)\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Dataset information\n",
        "        report.append(\"1. DATASET INFORMATION\")\n",
        "        report.append(\"-\" * 80)\n",
        "        report.append(f\"   • Total observations: {len(full_df)}\")\n",
        "        report.append(f\"   • Date range: {full_df['ds'].min().date()} to {full_df['ds'].max().date()}\")\n",
        "        report.append(f\"   • Training set size: {len(self.model_comparison.train_df)} days\")\n",
        "        report.append(f\"   • Test set size: {len(self.model_comparison.test_df)} days\")\n",
        "        report.append(f\"   • Mean sales: ${full_df['y'].mean():.2f}\")\n",
        "        report.append(f\"   • Std deviation: ${full_df['y'].std():.2f}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # Cross-validation strategy\n",
        "        report.append(\"2. CROSS-VALIDATION STRATEGY\")\n",
        "        report.append(\"-\" * 80)\n",
        "        report.append(\"   Strategy: Time Series Split with Rolling Window\")\n",
        "        report.append(f\"   • Initial training period:"
      ],
      "metadata": {
        "id": "t1YL2VuLL1Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ixvppwhwL06E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}